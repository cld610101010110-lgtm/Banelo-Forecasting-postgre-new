{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banelo Forecasting - ML Model Training\n",
    "\n",
    "This notebook trains machine learning models for inventory forecasting.\n",
    "\n",
    "## Steps:\n",
    "1. Upload CSV data files\n",
    "2. Explore and preprocess data\n",
    "3. Engineer features\n",
    "4. Train multiple models (Random Forest, XGBoost, LSTM)\n",
    "5. Evaluate and compare performance\n",
    "6. Export best model for Django integration\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q pandas numpy scikit-learn xgboost matplotlib seaborn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# Visualization settings\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Data Files\n",
    "\n",
    "Upload the CSV files exported from your Django app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Upload files directly\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "print(\"\\nâœ… Files uploaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Mount Google Drive (if you stored files there)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# data_path = '/content/drive/MyDrive/banelo_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"ðŸ“Š Loading data...\")\n",
    "sales_df = pd.read_csv('sales_data.csv')\n",
    "products_df = pd.read_csv('products_data.csv')\n",
    "daily_sales_df = pd.read_csv('daily_sales_aggregated.csv')\n",
    "\n",
    "# Convert date columns\n",
    "sales_df['order_date'] = pd.to_datetime(sales_df['order_date'])\n",
    "daily_sales_df['date'] = pd.to_datetime(daily_sales_df['date'])\n",
    "\n",
    "print(f\"\\nâœ… Data loaded successfully!\")\n",
    "print(f\"   - Sales records: {len(sales_df):,}\")\n",
    "print(f\"   - Products: {len(products_df):,}\")\n",
    "print(f\"   - Daily aggregates: {len(daily_sales_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data\n",
    "print(\"\\nðŸ“‹ Sales Data Preview:\")\n",
    "display(sales_df.head())\n",
    "\n",
    "print(\"\\nðŸ“¦ Products Data Preview:\")\n",
    "display(products_df.head())\n",
    "\n",
    "print(\"\\nðŸ“ˆ Daily Sales Aggregated Preview:\")\n",
    "display(daily_sales_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data statistics\n",
    "print(\"\\nðŸ“Š Data Statistics:\")\n",
    "print(\"\\nSales by Category:\")\n",
    "print(sales_df.groupby('category')['quantity'].agg(['count', 'sum', 'mean']))\n",
    "\n",
    "print(\"\\nTop 10 Products by Sales Volume:\")\n",
    "top_products = sales_df.groupby('product_name')['quantity'].sum().sort_values(ascending=False).head(10)\n",
    "print(top_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Sales over time\n",
    "plt.figure(figsize=(14, 6))\n",
    "daily_total = sales_df.groupby(sales_df['order_date'].dt.date)['quantity'].sum()\n",
    "plt.plot(daily_total.index, daily_total.values, marker='o', linewidth=2)\n",
    "plt.title('Total Daily Sales Over Time', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Quantity')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Sales by category\n",
    "plt.figure(figsize=(10, 6))\n",
    "category_sales = sales_df.groupby('category')['quantity'].sum().sort_values(ascending=False)\n",
    "sns.barplot(x=category_sales.values, y=category_sales.index, palette='viridis')\n",
    "plt.title('Total Sales by Category', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Total Quantity')\n",
    "plt.ylabel('Category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Top products\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_20 = sales_df.groupby('product_name')['quantity'].sum().sort_values(ascending=False).head(20)\n",
    "sns.barplot(x=top_20.values, y=top_20.index, palette='rocket')\n",
    "plt.title('Top 20 Products by Sales Volume', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Total Quantity Sold')\n",
    "plt.ylabel('Product')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(daily_df):\n",
    "    \"\"\"\n",
    "    Create features for ML model\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”§ Engineering features...\")\n",
    "    \n",
    "    df = daily_df.copy()\n",
    "    \n",
    "    # Sort by date\n",
    "    df = df.sort_values(['product_id', 'date'])\n",
    "    \n",
    "    # Time-based features\n",
    "    df['day_of_week'] = pd.to_datetime(df['date']).dt.dayofweek\n",
    "    df['day_of_month'] = pd.to_datetime(df['date']).dt.day\n",
    "    df['month'] = pd.to_datetime(df['date']).dt.month\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    df['week_of_year'] = pd.to_datetime(df['date']).dt.isocalendar().week\n",
    "    \n",
    "    # Rolling statistics (7-day window)\n",
    "    df['rolling_mean_7d'] = df.groupby('product_id')['total_quantity'].transform(\n",
    "        lambda x: x.rolling(window=7, min_periods=1).mean()\n",
    "    )\n",
    "    df['rolling_std_7d'] = df.groupby('product_id')['total_quantity'].transform(\n",
    "        lambda x: x.rolling(window=7, min_periods=1).std().fillna(0)\n",
    "    )\n",
    "    df['rolling_max_7d'] = df.groupby('product_id')['total_quantity'].transform(\n",
    "        lambda x: x.rolling(window=7, min_periods=1).max()\n",
    "    )\n",
    "    df['rolling_min_7d'] = df.groupby('product_id')['total_quantity'].transform(\n",
    "        lambda x: x.rolling(window=7, min_periods=1).min()\n",
    "    )\n",
    "    \n",
    "    # Rolling statistics (30-day window)\n",
    "    df['rolling_mean_30d'] = df.groupby('product_id')['total_quantity'].transform(\n",
    "        lambda x: x.rolling(window=30, min_periods=1).mean()\n",
    "    )\n",
    "    df['rolling_std_30d'] = df.groupby('product_id')['total_quantity'].transform(\n",
    "        lambda x: x.rolling(window=30, min_periods=1).std().fillna(0)\n",
    "    )\n",
    "    \n",
    "    # Lag features\n",
    "    df['lag_1d'] = df.groupby('product_id')['total_quantity'].shift(1).fillna(0)\n",
    "    df['lag_7d'] = df.groupby('product_id')['total_quantity'].shift(7).fillna(0)\n",
    "    df['lag_14d'] = df.groupby('product_id')['total_quantity'].shift(14).fillna(0)\n",
    "    \n",
    "    # Trend features\n",
    "    df['days_since_start'] = (pd.to_datetime(df['date']) - pd.to_datetime(df['date']).min()).dt.days\n",
    "    \n",
    "    # Category encoding\n",
    "    le = LabelEncoder()\n",
    "    df['category_encoded'] = le.fit_transform(df['category'])\n",
    "    \n",
    "    print(f\"   âœ… Created {len(df.columns)} features\")\n",
    "    \n",
    "    return df, le\n",
    "\n",
    "# Apply feature engineering\n",
    "featured_df, label_encoder = engineer_features(daily_sales_df)\n",
    "print(\"\\nâœ… Feature engineering complete!\")\n",
    "print(f\"\\nFeature columns: {list(featured_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "feature_columns = [\n",
    "    'day_of_week', 'day_of_month', 'month', 'is_weekend', 'week_of_year',\n",
    "    'rolling_mean_7d', 'rolling_std_7d', 'rolling_max_7d', 'rolling_min_7d',\n",
    "    'rolling_mean_30d', 'rolling_std_30d',\n",
    "    'lag_1d', 'lag_7d', 'lag_14d',\n",
    "    'days_since_start', 'category_encoded',\n",
    "    'num_transactions', 'avg_price'\n",
    "]\n",
    "\n",
    "target_column = 'total_quantity'\n",
    "\n",
    "# Prepare X and y\n",
    "X = featured_df[feature_columns].fillna(0)\n",
    "y = featured_df[target_column]\n",
    "\n",
    "print(f\"ðŸ“Š Training data shape: {X.shape}\")\n",
    "print(f\"ðŸ“Š Target data shape: {y.shape}\")\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Train set: {X_train.shape[0]} samples\")\n",
    "print(f\"âœ… Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Models\n",
    "\n",
    "We'll train 3 different models and compare performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Linear Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ¤– Training Linear Regression...\")\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "lr_mae = mean_absolute_error(y_test, y_pred_lr)\n",
    "lr_r2 = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"\\nâœ… Linear Regression Results:\")\n",
    "print(f\"   RMSE: {lr_rmse:.4f}\")\n",
    "print(f\"   MAE: {lr_mae:.4f}\")\n",
    "print(f\"   RÂ² Score: {lr_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŒ² Training Random Forest...\")\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "rf_mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "rf_r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"\\nâœ… Random Forest Results:\")\n",
    "print(f\"   RMSE: {rf_rmse:.4f}\")\n",
    "print(f\"   MAE: {rf_mae:.4f}\")\n",
    "print(f\"   RÂ² Score: {rf_r2:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š Top 10 Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance.head(15), palette='viridis')\n",
    "plt.title('Top 15 Feature Importances (Random Forest)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: XGBoost (High Performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸš€ Training XGBoost...\")\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "xgb_mae = mean_absolute_error(y_test, y_pred_xgb)\n",
    "xgb_r2 = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"\\nâœ… XGBoost Results:\")\n",
    "print(f\"   RMSE: {xgb_rmse:.4f}\")\n",
    "print(f\"   MAE: {xgb_mae:.4f}\")\n",
    "print(f\"   RÂ² Score: {xgb_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'XGBoost'],\n",
    "    'RMSE': [lr_rmse, rf_rmse, xgb_rmse],\n",
    "    'MAE': [lr_mae, rf_mae, xgb_mae],\n",
    "    'RÂ² Score': [lr_r2, rf_r2, xgb_r2]\n",
    "})\n",
    "\n",
    "print(\"\\nðŸ“Š MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "display(comparison_df)\n",
    "\n",
    "# Find best model\n",
    "best_idx = comparison_df['RÂ² Score'].idxmax()\n",
    "best_model_name = comparison_df.loc[best_idx, 'Model']\n",
    "print(f\"\\nðŸ† Best Model: {best_model_name}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# RMSE\n",
    "axes[0].bar(comparison_df['Model'], comparison_df['RMSE'], color=['#3498db', '#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Root Mean Squared Error (Lower is Better)', fontweight='bold')\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# MAE\n",
    "axes[1].bar(comparison_df['Model'], comparison_df['MAE'], color=['#3498db', '#2ecc71', '#e74c3c'])\n",
    "axes[1].set_title('Mean Absolute Error (Lower is Better)', fontweight='bold')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# RÂ² Score\n",
    "axes[2].bar(comparison_df['Model'], comparison_df['RÂ² Score'], color=['#3498db', '#2ecc71', '#e74c3c'])\n",
    "axes[2].set_title('RÂ² Score (Higher is Better)', fontweight='bold')\n",
    "axes[2].set_ylabel('RÂ² Score')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted (Random Forest)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5, s=30)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Values', fontsize=12)\n",
    "plt.ylabel('Predicted Values', fontsize=12)\n",
    "plt.title('Random Forest: Actual vs Predicted', fontsize=16, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plot\n",
    "residuals = y_test - y_pred_rf\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(y_pred_rf, residuals, alpha=0.5, s=30)\n",
    "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "plt.xlabel('Predicted Values', fontsize=12)\n",
    "plt.ylabel('Residuals', fontsize=12)\n",
    "plt.title('Residual Plot (Random Forest)', fontsize=16, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Model for Django Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best model to export (Random Forest recommended)\n",
    "final_model = rf_model\n",
    "model_name = 'Random Forest'\n",
    "\n",
    "# Create metadata dictionary\n",
    "model_metadata = {\n",
    "    'model_name': model_name,\n",
    "    'model_type': 'RandomForestRegressor',\n",
    "    'trained_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'training_samples': len(X_train),\n",
    "    'test_samples': len(X_test),\n",
    "    'feature_columns': feature_columns,\n",
    "    'metrics': {\n",
    "        'rmse': float(rf_rmse),\n",
    "        'mae': float(rf_mae),\n",
    "        'r2_score': float(rf_r2)\n",
    "    },\n",
    "    'feature_importance': feature_importance.to_dict('records')[:10]\n",
    "}\n",
    "\n",
    "# Package everything together\n",
    "model_package = {\n",
    "    'model': final_model,\n",
    "    'metadata': model_metadata,\n",
    "    'label_encoder': label_encoder,\n",
    "    'feature_columns': feature_columns\n",
    "}\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model_package, 'forecasting_model.pkl', compress=3)\n",
    "print(\"\\nâœ… Model saved successfully!\")\n",
    "print(f\"\\nðŸ“¦ Model: forecasting_model.pkl\")\n",
    "print(f\"   - Model Type: {model_name}\")\n",
    "print(f\"   - Training Samples: {len(X_train):,}\")\n",
    "print(f\"   - Test Samples: {len(X_test):,}\")\n",
    "print(f\"   - RMSE: {rf_rmse:.4f}\")\n",
    "print(f\"   - MAE: {rf_mae:.4f}\")\n",
    "print(f\"   - RÂ² Score: {rf_r2:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ“¥ Download this file and place it in: ml_models/forecasting_model.pkl\")\n",
    "print(\"\\nâœ… Then run: python integrate_ml_model.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model\n",
    "from google.colab import files\n",
    "files.download('forecasting_model.pkl')\n",
    "print(\"\\nâœ… Model downloaded! Ready for Django integration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Generate Sample Predictions (Preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample predictions for preview\n",
    "sample_predictions = []\n",
    "\n",
    "# Get unique products\n",
    "unique_products = featured_df[['product_id', 'product_name', 'category']].drop_duplicates()\n",
    "\n",
    "for _, product in unique_products.head(10).iterrows():\n",
    "    # Get latest features for this product\n",
    "    product_data = featured_df[featured_df['product_id'] == product['product_id']].tail(1)\n",
    "    \n",
    "    if len(product_data) > 0:\n",
    "        X_sample = product_data[feature_columns].fillna(0)\n",
    "        prediction = final_model.predict(X_sample)[0]\n",
    "        \n",
    "        sample_predictions.append({\n",
    "            'product_name': product['product_name'],\n",
    "            'category': product['category'],\n",
    "            'predicted_daily_usage': round(prediction, 2),\n",
    "            'current_avg': round(product_data['rolling_mean_7d'].values[0], 2)\n",
    "        })\n",
    "\n",
    "# Display predictions\n",
    "predictions_df = pd.DataFrame(sample_predictions)\n",
    "print(\"\\nðŸ”® SAMPLE PREDICTIONS (Top 10 Products)\")\n",
    "print(\"=\" * 70)\n",
    "display(predictions_df)\n",
    "print(\"\\nâœ… These predictions will be integrated into your Django dashboard!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Training Complete!\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. âœ… Download `forecasting_model.pkl`\n",
    "2. âœ… Place it in your Django project: `ml_models/forecasting_model.pkl`\n",
    "3. âœ… Run integration script: `python integrate_ml_model.py`\n",
    "4. âœ… Sync to Firebase: `python sync_predictions_to_firebase.py`\n",
    "5. âœ… View predictions in dashboard: `/dashboard/inventory/forecasting/`\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
